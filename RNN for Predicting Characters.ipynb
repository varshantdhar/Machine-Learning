{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/Anaconda3-5.0.1-el7-x86_64/envs/DL_GPU_cuda_9.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import pickle\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', default='./')\n",
    "parser.add_argument('--save_dir', default='./')\n",
    "# Dimension of hidden layer variables h and c\n",
    "parser.add_argument('--num_units', default=128*2)\n",
    "parser.add_argument('--batch_size', default=64)\n",
    "# Number of steps in each batch for training\n",
    "parser.add_argument('--num_steps', default=75)\n",
    "parser.add_argument('--num_epochs', default=30)\n",
    "# Time step\n",
    "parser.add_argument('--lr', default=0.002)\n",
    "# Number of possible inputs/outputs \n",
    "parser.add_argument('--num_chars')\n",
    "parser.add_argument('--num_batches',default=20)\n",
    "args, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start, end):\n",
    "    hrs, rem = divmod(end-start, 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    print('{:0>2} hours {:0>2} minutes {:05.2f} seconds'.format(int(hrs), int(mins), secs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLoader():\n",
    "\n",
    "    def __init__(self, data_dir, batch_size=64, seq_length=50, encoding='utf-8'):\n",
    "        self.data_dir = data_dir\n",
    "        self.encoding = encoding\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.input_file = os.path.join(data_dir, '/project/cmsc25025/Shakespear/tinyshakespeare.txt')\n",
    "        self.vocab_file = os.path.join(data_dir, '/project/cmsc25025/Shakespear/vocab.pkl')\n",
    "        # Numeric file of characters translated to indices.\n",
    "        self.tensor_file = os.path.join(data_dir, '/project/cmsc25025/Shakespear/data.npy')\n",
    "        \n",
    "        if not (os.path.exists(self.vocab_file) and os.path.exists(self.tensor_file)):\n",
    "            print('it seems we havent processed the text data yet: reading the shakespear')\n",
    "            self.preprocess(self.input_file, self.vocab_file, self.tensor_file)\n",
    "        else:\n",
    "            print('there are preprocessed data - lets load it')\n",
    "            self.load_preprocessed(self.vocab_file, self.tensor_file)\n",
    "\n",
    "        self.create_batches()\n",
    "        self.reset_batch_pointer()\n",
    "\n",
    "    # Create numeric file.\n",
    "    def preprocess(self, input_file=None, vocab_file=None, tensor_file=None, saveit=True):\n",
    "        if input_file is not None:\n",
    "            self.input_file = input_file\n",
    "        if vocab_file is not None:\n",
    "            self.vocab_file = vocab_file\n",
    "        if tensor_file is not None:\n",
    "            self.tensor_file = tensor_file\n",
    "\n",
    "        with open(self.input_file, 'r') as f:\n",
    "            data = f.read()\n",
    "        #data = data.lower()\n",
    "        self.total_length = len(data)\n",
    "        counter = collections.Counter(data)\n",
    "        count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "        self.chars, _ = zip(*count_pairs)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab_to_idx = dict(zip(self.chars, range(len(self.chars))))\n",
    "        self.idx_to_vocab = dict(zip(self.vocab_to_idx.values(), self.vocab_to_idx.keys()))\n",
    "\n",
    "        if saveit:\n",
    "            with open(self.vocab_file, 'wb') as f:  # saving dictionary so we don't compute it again\n",
    "                pickle.dump(self.chars, f)\n",
    "            self.tensor = np.array(list(map(self.vocab_to_idx.get, data)))\n",
    "            np.save(self.tensor_file, self.tensor)  # saving the numerified data\n",
    "    # Load numeric file create dictionaries for char2idx and back\n",
    "    def load_preprocessed(self, vocab_file=None, tensor_file=None):\n",
    "        if vocab_file is not None:\n",
    "            self.vocab_file = vocab_file\n",
    "        if tensor_file is not None:\n",
    "            self.tensor_file = tensor_file\n",
    "\n",
    "        with open(self.vocab_file, 'rb') as f:\n",
    "            self.chars = pickle.load(f)\n",
    "\n",
    "        # attributes\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(self.vocab_size)))\n",
    "        self.vocab_to_idx = dict(zip(self.chars, range(len(self.chars))))\n",
    "        self.idx_to_vocab = dict(zip(self.vocab_to_idx.values(), self.vocab_to_idx.keys()))\n",
    "        self.tensor = np.load(tensor_file)\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
    "            \n",
    "    # tensor size = the length of the entire data sequence\n",
    "    # divide into batch_size sub sequences and stack\n",
    "    # cut those by seq_length to produce batches of [batch size, seq_length] sized examples\n",
    "    def create_batches(self):\n",
    "\n",
    "        \n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
    "\n",
    "        if self.num_batches == 0:\n",
    "            assert False, 'Not enough data. Make seq_length and/or batch_size smaller'\n",
    "\n",
    "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]  # so we get an even divide\n",
    "        xdata = self.tensor\n",
    "        ydata = np.copy(self.tensor)\n",
    "\n",
    "        # ydata is one step ahead of x and last item is first item of x \n",
    "        # to get sequences of same length    \n",
    "        ydata[:-1] = xdata[1:] \n",
    "        ydata[-1] = xdata[0]\n",
    "\n",
    "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "        \n",
    "        self.train_num_batches=np.int32(self.num_batches*.8)\n",
    "        self.test_num_batches=self.num_batches-self.train_num_batches\n",
    "        self.train_x_batches=self.x_batches[0:self.train_num_batches]\n",
    "        self.train_y_batches=self.y_batches[0:self.train_num_batches]\n",
    "        self.test_x_batches=self.x_batches[self.train_num_batches:]\n",
    "        self.test_y_batches=self.y_batches[self.train_num_batches:]\n",
    "\n",
    "        # xdata: L length\n",
    "        # xdata reshaped: batch_size, (L/batch_size) length following natural indexing\n",
    "        # np.split: into num batches batches along the width(sentence)\n",
    "\n",
    "    def next_batch_train(self):\n",
    "        x, y = self.train_x_batches[self.pointer], self.train_y_batches[self.pointer]\n",
    "        self.pointer += 1\n",
    "        return x,y\n",
    "    \n",
    "    def next_batch_test(self):\n",
    "        x, y = self.test_x_batches[self.pointer], self.test_y_batches[self.pointer]\n",
    "        self.pointer += 1\n",
    "        return x,y\n",
    "\n",
    "    def reset_batch_pointer(self):\n",
    "        self.pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are preprocessed data - lets load it\n",
      "num chars 65\n",
      "num batches 232\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(args.data_dir, batch_size=args.batch_size, seq_length=args.num_steps)\n",
    "args.num_chars = loader.vocab_size\n",
    "print('num chars',args.num_chars)\n",
    "print('num batches',loader.num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBasicRNNCell(tf.contrib.rnn.BasicRNNCell):\n",
    "\n",
    "    def build(self, inputs_shape):\n",
    "\n",
    "        input_depth = inputs_shape[1].value\n",
    "        \n",
    "        self._kernel = self.add_variable(name=\"kernel_hidden\", shape=[input_depth + self._num_units, self._num_units])\n",
    "        self._bias = self.add_variable(name=\"bias_hidden\", shape=[self._num_units], initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        \"\"\"Most basic RNN: output = new_state = act(W * input + U * state + B).\"\"\"\n",
    "        \n",
    "        output = tf.tanh(tf.matmul(tf.concat([inputs, state], 1), self._kernel) + self._bias)\n",
    "\n",
    "        return output, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMStateTuple = collections.namedtuple(\"LSTMStateTuple\", (\"c\", \"h\"))\n",
    "\n",
    "class MyBasicLSTMCell(tf.contrib.rnn.BasicLSTMCell):\n",
    "\n",
    "    def build(self, inputs_shape):\n",
    "\n",
    "        input_depth = inputs_shape[1].value\n",
    "        self._kernel = self.add_variable(name=\"kernel\", shape=[input_depth + self._num_units, 4 * self._num_units])\n",
    "        self._bias = self.add_variable(name=\"bias\", shape=[4 * self._num_units], initializer=tf.zeros_initializer())\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "\n",
    "        one = tf.constant(1, dtype=tf.int32)\n",
    "        c, h = state\n",
    "\n",
    "        gate_inputs = tf.matmul(tf.concat([inputs, h], axis=1), self._kernel) + self._bias\n",
    "\n",
    "        input_gate_weights, input_weights, forget_gate_weights, output_gate_weights = tf.split(\n",
    "            value=gate_inputs, num_or_size_splits=4, axis=one)\n",
    "\n",
    "        # forget gating\n",
    "        forget_bias_tensor = tf.constant(1.0, dtype=forget_gate_weights.dtype)\n",
    "        forget_gate = tf.sigmoid(forget_gate_weights + forget_bias_tensor)\n",
    "        gated_memory = c * forget_gate\n",
    "\n",
    "        # input gating\n",
    "        processed_new_input = tf.tanh(input_weights)\n",
    "        input_gate = tf.sigmoid(input_gate_weights)\n",
    "        gated_input = input_gate * processed_new_input\n",
    "\n",
    "        # updating memory\n",
    "        new_c = gated_memory + gated_input\n",
    "\n",
    "        # output gating\n",
    "        processed_memory = tf.tanh(new_c)\n",
    "        output_gate = tf.sigmoid(output_gate_weights)\n",
    "        new_h = processed_memory * output_gate\n",
    "\n",
    "        new_state = tf.nn.rnn_cell.LSTMStateTuple(new_c, new_h)\n",
    "\n",
    "        return new_h, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(myLSTMCell,inputs,targets):\n",
    "\n",
    "    with tf.variable_scope('embedding_matrix'):\n",
    "        embedding = tf.get_variable('embedding', [args.num_chars, args.num_units])\n",
    "        embedded_inputs = tf.nn.embedding_lookup(embedding, inputs)\n",
    "        inputs_list = tf.unstack(embedded_inputs, axis=1)  # shape: a list of [batch_size, num_units] length num_steps\n",
    "\n",
    "    with tf.variable_scope('LSTMCell') as myscope:\n",
    "        cell = myLSTMCell(args.num_units)\n",
    "        init_state = cell.zero_state(args.batch_size, tf.float32)\n",
    "        state = init_state\n",
    "        outputs = []\n",
    "\n",
    "        for time_, input in enumerate(inputs_list):\n",
    "            if time_ > 0:\n",
    "                myscope.reuse_variables()\n",
    "           \n",
    "            output, state = cell(input, state)\n",
    "            outputs.append(output)\n",
    "    # All hidden outputs for each batch and every step in the batch are reshaped\n",
    "    # as one long matrix to be transformed to logits and compared to targets.\n",
    "        output_reshaped = tf.reshape(tf.concat(outputs, 1), [-1, args.num_units])\n",
    "\n",
    "        final_state = state\n",
    "\n",
    "    with tf.variable_scope('regression'):\n",
    "        W = tf.get_variable('W', [args.num_units, args.num_chars])\n",
    "        b = tf.get_variable('b', [args.num_chars], initializer=tf.constant_initializer(0.0))\n",
    "        logits = tf.matmul(output_reshaped, W) + b\n",
    "        prob = tf.nn.softmax(logits)\n",
    "\n",
    "    with tf.variable_scope('cost'):\n",
    "        targets_straightened = tf.reshape(targets, [-1])\n",
    "        crossentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                    labels=targets_straightened)\n",
    "        loss = tf.reduce_mean(crossentropy)\n",
    "        cost = loss/args.batch_size/args.num_steps\n",
    "\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(args.lr).minimize(loss)\n",
    "\n",
    "    with tf.variable_scope('saver'):\n",
    "        saver = tf.train.Saver()\n",
    "    return init_state, train_step, loss, final_state, saver, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(myCell,num_batches=None):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tf.reset_default_graph()\n",
    "    # Define the placeholders\n",
    "    with tf.variable_scope('placeholders'):\n",
    "            inputs = tf.placeholder(tf.int32, [args.batch_size, args.num_steps])\n",
    "            targets = tf.placeholder(tf.int32, [args.batch_size, args.num_steps])\n",
    "    # Create the network\n",
    "    init_state, train_step, loss, final_state, saver, prob=network(myCell,inputs,targets)\n",
    "    print('train_num_batches',loader.train_num_batches)\n",
    "    \n",
    "    if (num_batches is None):\n",
    "        num_batches=loader.train_num_batches\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "         \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # computation graph for training\n",
    "        training_losses = []\n",
    "\n",
    "        for epoch in range(args.num_epochs):\n",
    "            loader.reset_batch_pointer()\n",
    "            state_ = sess.run(init_state)\n",
    "            training_loss = 0\n",
    "\n",
    "            for batch in range(num_batches):\n",
    "\n",
    "                x, y = loader.next_batch_train()\n",
    "\n",
    "                feed_dict = dict()\n",
    "                feed_dict[inputs] = x\n",
    "                feed_dict[targets] = y\n",
    "                \n",
    "                if ('RNN' in myCell.__name__):\n",
    "                    feed_dict[init_state] = state_\n",
    "                else:\n",
    "                    feed_dict[init_state.c] = state_.c\n",
    "                    feed_dict[init_state.h] = state_.h\n",
    "\n",
    "                train_loss_, state_, _ = sess.run([loss, final_state, train_step], feed_dict=feed_dict)\n",
    "                training_loss += train_loss_\n",
    "            training_loss=training_loss/num_batches\n",
    "            print('epoch:', epoch, 'loss:',  training_loss)\n",
    "            training_losses.append(training_loss)\n",
    "        saver.save(sess, os.path.join(args.save_dir, 'saved_model'))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    timer(start_time, end_time)\n",
    "    plt.plot(training_losses)\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch Number\")\n",
    "    plt.show\n",
    "    return(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num_batches 185\n",
      "epoch: 0 loss: 2.382643204766351\n",
      "epoch: 1 loss: 1.8123692100112503\n",
      "epoch: 2 loss: 1.6373591429478414\n",
      "epoch: 3 loss: 1.5412706955059154\n",
      "epoch: 4 loss: 1.4793558262489936\n",
      "epoch: 5 loss: 1.435034162933762\n",
      "epoch: 6 loss: 1.40145216954721\n",
      "epoch: 7 loss: 1.3752302433993366\n",
      "epoch: 8 loss: 1.3530015655466028\n",
      "epoch: 9 loss: 1.334675806277507\n",
      "epoch: 10 loss: 1.317165546803861\n",
      "epoch: 11 loss: 1.3025770780202506\n",
      "epoch: 12 loss: 1.2908360455487224\n",
      "epoch: 13 loss: 1.280519200660087\n",
      "epoch: 14 loss: 1.2688266599500502\n",
      "epoch: 15 loss: 1.2587639499355008\n",
      "epoch: 16 loss: 1.2493483730264612\n",
      "epoch: 17 loss: 1.2405450756485399\n",
      "epoch: 18 loss: 1.2329727611026249\n",
      "epoch: 19 loss: 1.2271043880565746\n",
      "epoch: 20 loss: 1.221526725872143\n",
      "epoch: 21 loss: 1.2147658045227463\n",
      "epoch: 22 loss: 1.207052393861719\n",
      "epoch: 23 loss: 1.2005428468858874\n",
      "epoch: 24 loss: 1.194676914086213\n",
      "epoch: 25 loss: 1.1896039511706378\n",
      "epoch: 26 loss: 1.185378900734154\n",
      "epoch: 27 loss: 1.1822409945565302\n",
      "epoch: 28 loss: 1.1798627924274754\n",
      "epoch: 29 loss: 1.1791800556956111\n",
      "00 hours 04 minutes 13.49 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "re_lstm_basic = trainer(MyBasicLSTMCell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Try  a  few  priming  sentences  and  see  what  the  trained architecture produces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Synthesize(MyCell,init_string=\"None\"):\n",
    "    tf.reset_default_graph()\n",
    "    num_steps_bak=args.num_steps\n",
    "    batch_size_bak=args.batch_size\n",
    "    args.num_steps=1\n",
    "    args.batch_size=1\n",
    "    with tf.variable_scope('placeholders'):\n",
    "            inputs = tf.placeholder(tf.int32, [args.batch_size, args.num_steps])\n",
    "            targets = tf.placeholder(tf.int32, [args.batch_size, args.num_steps])\n",
    "    init_state, train_step, loss, final_state, saver, prob=network(MyCell,inputs,targets)\n",
    "\n",
    "    # Define initialization\n",
    "    if (init_string is None):\n",
    "        initialization = 'Where are you going today?'\n",
    "    else:\n",
    "        initialization = init_string\n",
    "    loader= TextLoader(args.data_dir, batch_size=1, seq_length=1)\n",
    "\n",
    "    forecast_data=np.array(list(map(loader.vocab_to_idx.get, initialization)))\n",
    "    print(forecast_data)\n",
    "    forecast_range = 100\n",
    "    top_k=5\n",
    " \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Load saved model\n",
    "        saver.restore(sess, 'saved_model')\n",
    "        state_ = sess.run(init_state)\n",
    "\n",
    "        # Run rnn on initialization data to get final hidden state before simulation\n",
    "        state_ = sess.run(init_state)\n",
    "        for i in range(forecast_data.shape[0]):\n",
    "\n",
    "            feed_dict = dict()\n",
    "            # Feed current predicted\n",
    "            feed_dict[inputs] = forecast_data[i].reshape(args.batch_size, args.num_steps)\n",
    "            if ('RNN' in MyCell.__name__):\n",
    "                feed_dict[init_state] = state_\n",
    "            else:\n",
    "                feed_dict[init_state.c] = state_.c\n",
    "                feed_dict[init_state.h] = state_.h\n",
    "            # Get new hidden state and prediction probabilities\n",
    "            predicted_prob, state_ = sess.run([prob, final_state], feed_dict=feed_dict)\n",
    "\n",
    "        # last state of this step becomes first state of simulation\n",
    "\n",
    "        for i in range(forecast_range):\n",
    "\n",
    "            feed_dict = dict()\n",
    "            # Feed current predicted\n",
    "            feed_dict[inputs] = forecast_data[-args.num_steps:].reshape(args.batch_size, args.num_steps)\n",
    "            if ('RNN' in MyCell.__name__):\n",
    "                feed_dict[init_state] = state_\n",
    "            else:\n",
    "                feed_dict[init_state.c] = state_.c\n",
    "                feed_dict[init_state.h] = state_.h\n",
    "            predicted_prob, state_ = sess.run([prob, final_state], feed_dict=feed_dict)\n",
    "\n",
    "            predicted_prob = predicted_prob.ravel()\n",
    "            # Simulate from top top_k probs\n",
    "            predicted_prob[np.argsort(predicted_prob)[:-top_k]] = 0\n",
    "            predicted_prob = predicted_prob/np.sum(predicted_prob)\n",
    "            sample = np.random.choice(args.num_chars, 1, p=predicted_prob)[0]\n",
    "\n",
    "\n",
    "            forecast_data = np.hstack((forecast_data, sample))\n",
    "\n",
    "    forecasted_chars = np.asarray([loader.idx_to_vocab[elem] for elem in forecast_data])\n",
    "\n",
    "    print(''.join(forecasted_chars))\n",
    "  \n",
    "    args.num_steps=num_steps_bak\n",
    "    args.batch_size=batch_size_bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are preprocessed data - lets load it\n",
      "[41  1 11 11  3 16  0  5  3 17  0  4  7  1  0 15  3 13 44  0 21  0  4 14\n",
      "  0 17  1]\n",
      "INFO:tensorflow:Restoring parameters from saved_model\n",
      "Hello, how are you? I am wep,\n",
      "Which they have seen to tell him. I hope he says\n",
      "Thy house wherein the seas of the word of heaven\n"
     ]
    }
   ],
   "source": [
    "Synthesize(MyBasicLSTMCell,\"Hello, how are you? I am we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are preprocessed data - lets load it\n",
      "[ 4 11  4  6 16  0 23  3  3  7  0 50  3  7  9]\n",
      "INFO:tensorflow:Restoring parameters from saved_model\n",
      "alas, poor Yorin\n",
      "Too marry my body that has like me,\n",
      "And then I was a great country is a day,\n",
      "And see the wife's me\n"
     ]
    }
   ],
   "source": [
    "Synthesize(MyBasicLSTMCell,\"alas, poor Yori\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are preprocessed data - lets load it\n",
      "[29  5  1  7  1 30  6  0  4  0  2  9 12  1  0  9  8  0  2  5  1  0  4 18\n",
      " 18  4  9  7  6  0  3 18  0]\n",
      "INFO:tensorflow:Restoring parameters from saved_model\n",
      "There's a tide in the affairs of it,\n",
      "And that thou seem'st the world to him, and\n",
      "I have thy more than a world as more to\n",
      "continue in \n"
     ]
    }
   ],
   "source": [
    "Synthesize(MyBasicLSTMCell,\"There's a tide in the affairs of \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test set and estimate the error on prediction in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tester(MyCell, num_batches=None):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.variable_scope('placeholders'):\n",
    "            inputs = tf.placeholder(tf.int32, [args.batch_size, args.num_steps])\n",
    "            targets = tf.placeholder(tf.int32, [args.batch_size, args.num_steps])\n",
    "    init_state, train_step, loss, final_state, saver, prob=network(MyCell,inputs,targets)\n",
    "\n",
    "    # Define initialization\n",
    "    initialization = 'Where are you going today?'\n",
    "    loader= TextLoader(args.data_dir, batch_size=args.batch_size, seq_length=args.num_steps)\n",
    "\n",
    "    forecast_data=np.array(list(map(loader.vocab_to_idx.get, initialization)))\n",
    "    print(forecast_data)\n",
    "    forecast_range = 100\n",
    "    top_k=5\n",
    " \n",
    "    if (num_batches is None):\n",
    "        num_batches=loader.test_num_batches\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Load saved model\n",
    "        saver.restore(sess, 'saved_model')\n",
    "        state_ = sess.run(init_state)\n",
    "        \n",
    "        loader.reset_batch_pointer()\n",
    "        \n",
    "         # Get test error loss\n",
    "        test_loss = 0\n",
    "        print('num_batches',num_batches)\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "\n",
    "            x, y = loader.next_batch_test()\n",
    "\n",
    "            feed_dict = dict()\n",
    "            feed_dict[inputs] = x\n",
    "            feed_dict[targets] = y\n",
    "\n",
    "            if ('RNN' in MyCell.__name__):\n",
    "                feed_dict[init_state] = state_\n",
    "            else:\n",
    "                feed_dict[init_state.c] = state_.c\n",
    "                feed_dict[init_state.h] = state_.h\n",
    "\n",
    "            test_loss_, state_= sess.run([loss, final_state], feed_dict=feed_dict)\n",
    "            test_loss += test_loss_\n",
    "        test_loss=test_loss/num_batches\n",
    "        print('test loss:',  test_loss)\n",
    "\n",
    "    return(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are preprocessed data - lets load it\n",
      "[39  5  1  7  1  0  4  7  1  0 15  3 13  0 20  3  9  8 20  0  2  3 12  4\n",
      " 15 44]\n",
      "INFO:tensorflow:Restoring parameters from saved_model\n",
      "num_batches 47\n",
      "test loss: 1.4172643118716302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4172643118716302"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tester(MyBasicLSTMCell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run  the  same  experiment  with  the  basic  RNN  architecture.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num_batches 185\n",
      "epoch: 0 loss: 2.2770076835477675\n",
      "epoch: 1 loss: 1.8400818006412403\n",
      "epoch: 2 loss: 1.690681683694994\n",
      "epoch: 3 loss: 1.6091771306218328\n",
      "epoch: 4 loss: 1.5582162367331016\n",
      "epoch: 5 loss: 1.5220786088221783\n",
      "epoch: 6 loss: 1.4946965578440072\n",
      "epoch: 7 loss: 1.473355000083511\n",
      "epoch: 8 loss: 1.4562016783533869\n",
      "epoch: 9 loss: 1.4421293168454556\n",
      "epoch: 10 loss: 1.4303878545761108\n",
      "epoch: 11 loss: 1.4203908823631906\n",
      "epoch: 12 loss: 1.4117130878809336\n",
      "epoch: 13 loss: 1.4045269953237998\n",
      "epoch: 14 loss: 1.3979167699813844\n",
      "epoch: 15 loss: 1.3913341064710876\n",
      "epoch: 16 loss: 1.3861676383662869\n",
      "epoch: 17 loss: 1.3815159140406428\n",
      "epoch: 18 loss: 1.3765611944971858\n",
      "epoch: 19 loss: 1.372133697045816\n",
      "epoch: 20 loss: 1.3681902241062474\n",
      "epoch: 21 loss: 1.3646762757687956\n",
      "epoch: 22 loss: 1.3615674714784365\n",
      "epoch: 23 loss: 1.3589485555081755\n",
      "epoch: 24 loss: 1.3567184010067501\n",
      "epoch: 25 loss: 1.3547011285214812\n",
      "epoch: 26 loss: 1.3528355682218396\n",
      "epoch: 27 loss: 1.3512542118897308\n",
      "epoch: 28 loss: 1.3501659618841635\n",
      "epoch: 29 loss: 1.3487160708453205\n",
      "00 hours 01 minutes 45.43 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "re_rnn_basic = trainer(MyBasicRNNCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are preprocessed data - lets load it\n",
      "[39  5  1  7  1  0  4  7  1  0 15  3 13  0 20  3  9  8 20  0  2  3 12  4\n",
      " 15 44]\n",
      "INFO:tensorflow:Restoring parameters from saved_model\n",
      "num_batches 47\n",
      "test loss: 1.4619141994638647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4619141994638647"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tester(MyBasicRNNCell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training errors start at similar points for the initial epochs in both the RNN and LSTM models - however, in the LSTM model the training loss reduces to 1.18 at the 30th epoch whereas in the RNN model, the training loss only reduces to 1.46 at the 30th epoch. This could be because RNN uses 1/4th of the variables - leading to the time taken to calculate training loss reducing substantially. The testing loss is slightly lower in the LSTM model as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
