{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('labeled.json','r')\n",
    "brv=[]\n",
    "\n",
    "for line in f:\n",
    "    af = json.loads(line)\n",
    "    brv.append(af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_50.json', 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "    p = len(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(brv)\n",
    "indicator = (df['overall'] > 14).astype(int)\n",
    "by_beer = df[['beer_name', 'overall']].groupby('beer_name')\n",
    "by_brewer = df[['brewer', 'overall']].groupby('brewer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_mean = by_beer.mean()\n",
    "beer_median = by_beer.median()\n",
    "beer_sd = by_beer.std()\n",
    "\n",
    "\n",
    "brewer_mean = by_brewer.mean()\n",
    "brewer_median = by_brewer.median()\n",
    "brewer_std = by_brewer.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "beer_mean.columns = ['Beer_mean']\n",
    "beer_median.columns = ['Beer_median']\n",
    "beer_sd.columns = ['Beer_sd']\n",
    "\n",
    "brewer_mean.columns = ['brewer_mean']\n",
    "brewer_median.columns = ['brewer_median']\n",
    "brewer_std.columns = ['brewer_std']\n",
    "\n",
    "beer = beer_mean.join([beer_median, beer_sd],how='outer')\n",
    "beer = beer[np.isfinite(beer['Beer_sd'])]\n",
    "brewer = brewer_mean.join([brewer_median, brewer_std], how='outer')\n",
    "brewer = brewer[np.isfinite(brewer['brewer_std'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewer_mean</th>\n",
       "      <th>brewer_median</th>\n",
       "      <th>brewer_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6958.000000</td>\n",
       "      <td>6958.000000</td>\n",
       "      <td>6958.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.149545</td>\n",
       "      <td>12.331417</td>\n",
       "      <td>2.346387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.995206</td>\n",
       "      <td>2.086554</td>\n",
       "      <td>0.909007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.333333</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.844266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.445528</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.301872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.386201</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.801796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.250000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>9.899495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brewer_mean  brewer_median   brewer_std\n",
       "count  6958.000000    6958.000000  6958.000000\n",
       "mean     12.149545      12.331417     2.346387\n",
       "std       1.995206       2.086554     0.909007\n",
       "min       1.000000       1.000000     0.000000\n",
       "25%      11.333333      12.000000     1.844266\n",
       "50%      12.445528      13.000000     2.301872\n",
       "75%      13.386201      14.000000     2.801796\n",
       "max      19.250000      19.500000     9.899495"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "brewer.head(n)\n",
    "brewer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the standard deviation is generally low with the 50th percentile standard deviation at 2.34. Hence all people have somewhat similar taste when it comes breweries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beer_mean</th>\n",
       "      <th>Beer_median</th>\n",
       "      <th>Beer_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72858.000000</td>\n",
       "      <td>72858.000000</td>\n",
       "      <td>72858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.648817</td>\n",
       "      <td>12.754262</td>\n",
       "      <td>1.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.311643</td>\n",
       "      <td>2.387881</td>\n",
       "      <td>1.056971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.545455</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.258306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.819320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.445599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.727922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Beer_mean   Beer_median       Beer_sd\n",
       "count  72858.000000  72858.000000  72858.000000\n",
       "mean      12.648817     12.754262      1.915800\n",
       "std        2.311643      2.387881      1.056971\n",
       "min        1.000000      1.000000      0.000000\n",
       "25%       11.545455     12.000000      1.258306\n",
       "50%       13.000000     13.000000      1.819320\n",
       "75%       14.200000     14.000000      2.445599\n",
       "max       19.500000     20.000000     12.727922"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "beer.head(n)\n",
    "beer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the standard deviation is generally low with the 50th percentile standard deviation at 1.92. Hence all people have somewhat similar taste when it comes to beers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import string \n",
    "import re\n",
    "\n",
    "\n",
    "def clean_and_split(s):\n",
    "     # encode to UTF-8, convert to lowercase and translate all hyphens and\n",
    "     # punctuation to whitespace\n",
    "    s = s.encode('utf-8').lower().replace('-',' ').translate(None, string.punctuation)\n",
    "     # replace \\r\\n\n",
    "    s = re.sub('(\\r\\n)+',' ',s)\n",
    "     # replace whitespace substrings with one whitespace and remove\n",
    "     # leading/trailing whitespaces\n",
    "    s = re.sub(' +',' ',s.strip())\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for word in vocabulary:\n",
    "    vocabulary[word] = (vocabulary[word], i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].map(clean_and_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [on, tap, at, the, springfield, pa, location, ...\n",
       "1    [on, tap, at, the, john, harvards, in, springf...\n",
       "2    [updated, feb, 19, 2003, springfield, pa, ive,...\n",
       "3    [on, tap, the, springfield, pa, location, bill...\n",
       "4    [springfield, pa, location, poured, an, opaque...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "reviews.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(reviews, vocab):\n",
    "    indptr = [0]\n",
    "    indices = [] \n",
    "    data = []\n",
    "    for idx, d in pd.Series.iteritems(reviews):\n",
    "        for term in d:\n",
    "            if term in vocab:\n",
    "                index = vocab[term][1]\n",
    "                indices.append(index)\n",
    "                data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    print(len(data), len(indices), len(indptr))\n",
    "    return csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(reviews.shape[0] * 0.7)\n",
    "val_index = int(reviews.shape[0] * 0.85)\n",
    "\n",
    "train_reviews = reviews[:train_index]\n",
    "train_indicators = indicator[:train_index]\n",
    "\n",
    "val_reviews = reviews[train_index+1:val_index]\n",
    "val_indicators = indicator[train_index + 1:val_index]\n",
    "\n",
    "test_reviews = reviews[val_index:]\n",
    "test_indicators = indicator[val_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10698811, 10698811, 372952)\n"
     ]
    }
   ],
   "source": [
    "val_features = features(val_reviews, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49010443, 49010443, 1740444)\n"
     ]
    }
   ],
   "source": [
    "train_features = features(train_reviews, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Logistic Regression using Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "lm = LogisticRegression(penalty='l2', C=0.001)\n",
    "t0 = time.time()\n",
    "lm.fit(train_features, train_indicators)\n",
    "print(\"Training time: \", time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training time: ', 137.30983901023865)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(loss='hinge', C=0.01)\n",
    "t0 = time.time()\n",
    "svc.fit(train_features, train_indicators)\n",
    "print(\"Training time: \", time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Loss v Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_lm = lm.predict(val_features)\n",
    "acc_lm = accuracy_score(val_indicators, y_pred_lm, normalize=False) / float(val_indicators.size)\n",
    "y_pred_svc = svc.predict(val_features)\n",
    "acc_svc = accuracy_score(val_indicators, y_pred_svc, normalize=False) / float(val_indicators.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regrssion Accuracy: 0.780030\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regrssion Accuracy: %f\" % acc_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Accuracy 0.789492\n"
     ]
    }
   ],
   "source": [
    "print(\"LinearSVC Accuracy %f\" % acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying C changes the accuracy of both models. I find the highest prediction accuracy when C is at 1, however this creates a tradeoff as the time taken increases. A higher C leads to a much higher model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_likelihood(features, target, weights):\n",
    "    scores = np.dot(features, weights)\n",
    "    ll = np.sum( target*scores - np.log(1 + np.exp(scores)) )\n",
    "    return ll\n",
    "\n",
    "def logit(scores):\n",
    "    return 1 / (1 + (1 + np.expm1(-scores)))\n",
    "\n",
    "def logistic_regression(features, target, num_steps, learning_rate):\n",
    "        \n",
    "    weights = np.zeros(features.shape[1])\n",
    "    \n",
    "    for step in xrange(num_steps):\n",
    "        scores = np.dot(features, weights)\n",
    "        predictions = logit(scores)\n",
    "\n",
    "        output_error_signal = target - predictions\n",
    "        gradient = np.dot(features.T, output_error_signal)\n",
    "        weights += learning_rate * gradient\n",
    "        \n",
    "        if step % 10000 == 0:\n",
    "            print log_likelihood(features, target, weights)\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = logistic_regression(val_features[:1000], val_indicators[:1000], num_steps=3000, learning_rate=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_features = df[['appearance', 'aroma', 'palate', 'style', 'taste']]\n",
    "score_logit = LogisticRegression(penalty='l2', C=0.001)\n",
    "\n",
    "train_index = int(reviews.shape[0] * 0.7)\n",
    "val_index = int(reviews.shape[0] * 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ece6a7440084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscore_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_indicators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_pred_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0macc_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_indicators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_indicators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_scores = score_features[train_index+1:val_index]\n",
    "\n",
    "score_logit.fit(val_features, val_indicators)\n",
    "y_pred_all = score_logit.predict(val_scores)\n",
    "acc_all = accuracy_score(val_indicators, y_pred_all, normalize=False) / float(val_indicators.size)\n",
    "print(\"Logistic Regrssion Accuracy: %f\" % acc_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
